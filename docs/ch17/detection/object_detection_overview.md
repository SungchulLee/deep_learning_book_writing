# PyTorch Object Detection Tutorial for Undergraduates

Welcome! This tutorial package contains four progressively challenging examples of object detection using PyTorch. Each example is fully commented and designed to help you master object detection from fundamentals to advanced techniques.

## ğŸ“š What is Object Detection?

Object detection is a computer vision task that involves:
1. **Identifying** what objects are in an image (classification)
2. **Localizing** where they are (bounding boxes)
3. **Handling** multiple objects simultaneously

**Difference from Other Tasks:**
```
Classification:  "There's a dog"
Segmentation:   "These pixels are the dog"
Detection:      "There's a dog at coordinates (x=100, y=150, w=200, h=300)"
```

**Applications:**
- ğŸš— **Autonomous Driving**: Detect cars, pedestrians, traffic signs
- ğŸ“¦ **Retail**: Product detection, inventory management
- ğŸ¥ **Medical**: Tumor localization, organ detection
- ğŸ“± **Mobile Apps**: Face detection, AR filters
- ğŸ® **Gaming**: Player tracking, gesture recognition
- ğŸ”’ **Security**: Intrusion detection, person tracking
- ğŸ­ **Manufacturing**: Defect detection, quality control
- ğŸ“¸ **Photography**: Auto-focus, subject detection

## ğŸ¯ Key Concepts

### 1. Bounding Box
A rectangle defined by 4 coordinates:
```
[x, y, width, height]  or  [x_min, y_min, x_max, y_max]

Example:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â† Bounding box around dog
â”‚   â”‚  ğŸ•     â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Intersection over Union (IoU)
Measures overlap between predicted and ground truth boxes:
```
IoU = Area of Overlap / Area of Union

Example:
Predicted Box âˆ© Ground Truth Box
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  = IoU
Predicted Box âˆª Ground Truth Box

IoU > 0.5: Good detection
IoU > 0.7: Great detection
IoU > 0.9: Excellent detection
```

### 3. Non-Maximum Suppression (NMS)
Removes duplicate detections of the same object:
```
Before NMS:          After NMS:
â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚  â”‚  â”‚    â†’     â”‚  Dog   â”‚
â””â”€â”€â”´â”€â”€â”´â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
3 overlapping boxes  1 best box
```

### 4. Confidence Score
How certain the model is about the detection:
```
Confidence = P(object) Ã— IoU(pred, truth)

Example:
Dog: 95% confidence âœ“ Keep
Cat: 30% confidence âœ— Discard (below threshold)
```

## ğŸ“‚ Project Structure

```
pytorch_object_detection_tutorial/
â”‚
â”œâ”€â”€ README.md (this file)
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ example_1_basic_detection/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ basic_object_detection.py
â”‚
â”œâ”€â”€ example_2_yolo_detection/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ yolo_detection.py
â”‚
â”œâ”€â”€ example_3_custom_detection/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ custom_object_detection.py
â”‚
â””â”€â”€ example_4_advanced_techniques/
    â”œâ”€â”€ README.md
    â””â”€â”€ advanced_detection.py
```

## ğŸ“ Examples Overview

### Example 1: Basic Object Detection Concepts
**Difficulty: â­ Beginner**

Learn fundamental concepts by building a simple detector from scratch.

**Key Concepts:**
- Bounding box representation
- IoU calculation
- Sliding window detection (naive approach)
- Understanding anchor boxes
- Basic NMS implementation

**What You'll Build:**
A simple single-object detector on synthetic data to understand core concepts.

### Example 2: YOLO Detection
**Difficulty: â­â­ Intermediate**

Learn to use modern YOLO (You Only Look Once) architecture.

**Key Concepts:**
- YOLO architecture overview
- Grid-based detection
- Using pre-trained models (YOLOv5/YOLOv8)
- Transfer learning for detection
- COCO dataset and annotations

**What You'll Build:**
Object detector using pre-trained YOLO models on standard datasets.

### Example 3: Custom Object Detection
**Difficulty: â­â­â­ Intermediate-Advanced**

Train detectors on your own custom objects.

**Key Concepts:**
- Data annotation (bounding boxes)
- Creating custom datasets
- Training YOLO from scratch
- Data augmentation for detection
- Handling class imbalance
- Model evaluation (mAP, precision, recall)

**What You'll Build:**
Custom object detector trained on your specific objects.

### Example 4: Advanced Detection Techniques
**Difficulty: â­â­â­â­ Advanced**

Master state-of-the-art techniques for production systems.

**Key Concepts:**
- Multi-scale detection
- Anchor-free detection
- Real-time optimization
- Tracking (simple object tracking)
- Advanced NMS variants
- Model quantization and optimization
- TensorRT/ONNX export

**What You'll Build:**
Production-ready detector with advanced optimizations.

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- Basic understanding of CNNs and PyTorch
- Completed transfer learning tutorial (recommended)
- GPU recommended (but not required)

### Installation

1. Install the required packages:
```bash
pip install -r requirements.txt
```

2. Start with Example 1 and progress through the examples in order.

### Running the Examples

Each example is self-contained and can be run independently:

```bash
# Example 1
cd example_1_basic_detection
python basic_object_detection.py

# Example 2
cd example_2_yolo_detection
python yolo_detection.py

# Example 3
cd example_3_custom_detection
python custom_object_detection.py

# Example 4
cd example_4_advanced_techniques
python advanced_detection.py
```

## ğŸ“– Learning Path

We recommend following this learning path:

1. **Start with Example 1**: Understand bounding boxes, IoU, and NMS
2. **Move to Example 2**: Learn YOLO architecture and pre-trained models
3. **Practice with Example 3**: Train on your own custom objects
4. **Master Example 4**: Implement advanced techniques for production

## ğŸ’¡ Object Detection Architectures

### One-Stage Detectors (Fast)
- **YOLO (You Only Look Once)**: Fast, real-time detection
- **SSD (Single Shot Detector)**: Multi-scale detection
- **RetinaNet**: Focal loss for class imbalance

**Advantages:**
- âš¡ Very fast (real-time capable)
- ğŸ¯ Good accuracy
- ğŸ’» Simpler architecture

**Use When:** Speed is critical (video, real-time)

### Two-Stage Detectors (Accurate)
- **Faster R-CNN**: Region proposals â†’ classification
- **Mask R-CNN**: Adds segmentation masks
- **Cascade R-CNN**: Multi-stage refinement

**Advantages:**
- ğŸ¯ Higher accuracy
- ğŸ“ Better localization
- ğŸ” Better for small objects

**Use When:** Accuracy is critical (medical, autonomous driving)

### Comparison

| Architecture | Speed | Accuracy | Use Case |
|-------------|-------|----------|----------|
| **YOLOv8** | âš¡âš¡âš¡ | ğŸ¯ğŸ¯ | Real-time video |
| **YOLOv5** | âš¡âš¡âš¡ | ğŸ¯ğŸ¯ | General purpose |
| **Faster R-CNN** | âš¡ | ğŸ¯ğŸ¯ğŸ¯ | High accuracy needed |
| **RetinaNet** | âš¡âš¡ | ğŸ¯ğŸ¯ğŸ¯ | Class imbalance |
| **EfficientDet** | âš¡âš¡ | ğŸ¯ğŸ¯ğŸ¯ | Mobile/edge devices |

## ğŸ“ Evaluation Metrics

### 1. Intersection over Union (IoU)
```
IoU = Area of Overlap / Area of Union
```
- Measures localization accuracy
- Threshold typically 0.5 or 0.75

### 2. Precision
```
Precision = True Positives / (True Positives + False Positives)
```
- "Of all detections, how many were correct?"
- Higher = fewer false alarms

### 3. Recall
```
Recall = True Positives / (True Positives + False Negatives)
```
- "Of all objects, how many did we find?"
- Higher = fewer missed objects

### 4. Average Precision (AP)
- Area under Precision-Recall curve
- AP@50: IoU threshold of 0.5
- AP@75: IoU threshold of 0.75

### 5. mean Average Precision (mAP)
```
mAP = Average of AP across all classes
```
- **The standard metric for object detection**
- mAP@50: IoU threshold 0.5
- mAP@50:95: Average across IoU thresholds 0.5 to 0.95

## ğŸ”§ Common Challenges & Solutions

### Challenge 1: Small Objects
**Problem:** Small objects are hard to detect
**Solutions:**
- Multi-scale training
- Feature pyramid networks
- Higher resolution input
- Specific augmentation for small objects

### Challenge 2: Class Imbalance
**Problem:** Some classes have many more examples
**Solutions:**
- Focal loss
- Class-balanced sampling
- Data augmentation for rare classes
- Weighted loss functions

### Challenge 3: Overlapping Objects
**Problem:** Multiple objects close together
**Solutions:**
- Better NMS (Soft-NMS, DIoU-NMS)
- Lower IoU threshold for NMS
- Instance segmentation instead

### Challenge 4: Speed vs Accuracy
**Problem:** Real-time needs vs accuracy
**Solutions:**
- Model quantization
- Pruning
- Smaller backbones
- TensorRT optimization
- ONNX export

### Challenge 5: False Positives
**Problem:** Too many incorrect detections
**Solutions:**
- Increase confidence threshold
- Hard negative mining
- Better augmentation
- More training data

## ğŸ’¡ Tips for Success

1. **Start Simple**: Begin with 2-3 classes before scaling up
2. **Visualize Everything**: Always plot predictions to debug
3. **Good Annotations**: Quality matters more than quantity
4. **Use Pre-trained Models**: Transfer learning is crucial
5. **Monitor mAP**: Don't rely only on loss
6. **Balance Dataset**: Each class needs sufficient examples
7. **Augment Heavily**: Especially for small datasets
8. **Test Edge Cases**: Corner cases, occlusions, poor lighting

## ğŸ“š Datasets for Practice

**For Learning:**
- **PASCAL VOC**: 20 object classes, ~20K images
- **COCO**: 80 classes, 330K images (gold standard)
- **Open Images**: 600 classes, 9M images (huge)

**Domain-Specific:**
- **KITTI**: Autonomous driving
- **Cityscapes**: Urban street scenes
- **VisDrone**: Drone footage
- **DOTA**: Aerial images
- **DeepFashion**: Fashion items
- **Global Wheat Detection**: Agriculture

**Create Your Own:**
- Use annotation tools: LabelImg, CVAT, Roboflow
- Start with 100-200 images per class
- Ensure diversity in backgrounds, angles, lighting

## ğŸ› ï¸ Annotation Tools

1. **LabelImg**: Simple, beginner-friendly
2. **CVAT**: Professional, team collaboration
3. **Roboflow**: Web-based, auto-annotation
4. **Labelbox**: Enterprise solution
5. **VGG Image Annotator**: Lightweight

## ğŸ“Š Performance Benchmarks

**COCO Test-dev (80 classes):**

| Model | mAP | FPS | Parameters |
|-------|-----|-----|------------|
| YOLOv8x | 53.9% | 280 | 68M |
| YOLOv7 | 51.2% | 161 | 37M |
| YOLOv5x | 50.7% | 238 | 86M |
| EfficientDet-D7 | 52.2% | 5.4 | 52M |
| Faster R-CNN | 42.0% | 5 | 42M |

*FPS measured on NVIDIA V100*

## ğŸ¯ What You'll Learn

By completing all examples, you will:
- âœ… Understand bounding box detection fundamentals
- âœ… Implement IoU and NMS from scratch
- âœ… Use YOLO for object detection
- âœ… Train custom object detectors
- âœ… Evaluate models using mAP
- âœ… Handle class imbalance and small objects
- âœ… Optimize for real-time inference
- âœ… Deploy detection models to production

## ğŸš€ Real-World Applications

### Autonomous Driving
```python
# Detect: vehicles, pedestrians, traffic lights, signs
â†’ Safe navigation decisions
```

### Retail Analytics
```python
# Detect: products on shelves, customer behavior
â†’ Inventory management, marketing insights
```

### Medical Imaging
```python
# Detect: tumors, lesions, anatomical structures
â†’ Assist diagnosis, treatment planning
```

### Security & Surveillance
```python
# Detect: people, vehicles, suspicious objects
â†’ Alert systems, access control
```

### Agriculture
```python
# Detect: crops, diseases, weeds, pests
â†’ Precision farming, yield optimization
```

## âš ï¸ Important Notes

- Object detection is more computationally intensive than classification
- GPU highly recommended for training (CPU for inference is okay)
- Annotation is time-consuming but critical
- Start with pre-trained models and fine-tune
- mAP is the standard metric, not accuracy
- NMS is crucial for good results

## ğŸ“§ Next Steps After This Tutorial

After mastering object detection, you can explore:
1. **Instance Segmentation**: Mask R-CNN (detection + segmentation)
2. **Object Tracking**: Track objects across video frames
3. **3D Object Detection**: Detect in 3D space
4. **Keypoint Detection**: Pose estimation
5. **Video Object Detection**: Temporal information
6. **Panoptic Segmentation**: Semantic + instance segmentation

---

**Happy Detecting! ğŸ¯**

If you find these examples helpful, consider sharing them with fellow students or contributing improvements!

## ğŸ“ License

This educational material is provided as-is for learning purposes. Pre-trained models and datasets may have their own licenses.
