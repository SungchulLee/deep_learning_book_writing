# Disentanglement

Learning latent representations where individual dimensions correspond to independent, interpretable factors of variation.

---

## Overview

**What you'll learn:**

- What disentangled representations are and why they matter
- Metrics for measuring disentanglement
- Techniques for encouraging disentanglement in autoencoders
- Connection to β-VAE and information-theoretic approaches
- Practical evaluation of factor isolation quality

---

## Mathematical Foundation

### Definition

A representation $z = f(x) \in \mathbb{R}^k$ is **disentangled** if each dimension $z_i$ captures a single, independent factor of variation in the data. Formally, if the data is generated by independent factors $v = (v_1, \ldots, v_m)$, then a disentangled representation satisfies:

$$\frac{\partial z_i}{\partial v_j} \neq 0 \text{ for at most one } j$$

In other words, changing one generative factor $v_j$ should affect at most one latent dimension $z_i$.

### Why Disentanglement Matters

| Benefit | Description |
|---------|-------------|
| **Interpretability** | Each latent dimension has a clear semantic meaning |
| **Generalization** | Compositional understanding of factors transfers to new combinations |
| **Controllability** | Can manipulate individual factors without affecting others |
| **Robustness** | Independent factors are less susceptible to spurious correlations |

### Entangled vs Disentangled

Consider handwritten digits with factors: digit identity, stroke width, slant angle.

**Entangled:** Changing $z_1$ simultaneously affects digit identity, width, and slant.

**Disentangled:** $z_1$ controls only digit identity, $z_2$ controls only stroke width, $z_3$ controls only slant.

---

## Measuring Disentanglement

### Axis Alignment Score

For each latent dimension, compute how much variance it explains for each known factor. A perfectly disentangled representation has each dimension maximally aligned with exactly one factor:

```python
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score


def measure_axis_alignment(model, data_loader, device, num_factors=10):
    """
    Measure axis alignment: for each latent dimension, how strongly
    does it correlate with each known factor (e.g., digit class)?
    
    Returns a (latent_dim × num_factors) correlation matrix.
    """
    model.eval()
    
    latents = []
    labels = []
    
    with torch.no_grad():
        for images, targets in data_loader:
            images = images.view(images.size(0), -1).to(device)
            z = model.encode(images)
            latents.append(z.cpu().numpy())
            labels.append(targets.numpy())
    
    latents = np.concatenate(latents)
    labels = np.concatenate(labels)
    
    latent_dim = latents.shape[1]
    
    # One-hot encode labels for correlation
    label_onehot = np.eye(num_factors)[labels]
    
    # Correlation between each latent dim and each factor
    correlation_matrix = np.zeros((latent_dim, num_factors))
    
    for i in range(latent_dim):
        for j in range(num_factors):
            correlation_matrix[i, j] = abs(
                np.corrcoef(latents[:, i], label_onehot[:, j])[0, 1]
            )
    
    return correlation_matrix


def visualize_disentanglement(correlation_matrix):
    """Visualize the latent-factor correlation matrix."""
    plt.figure(figsize=(12, 8))
    plt.imshow(correlation_matrix, aspect='auto', cmap='Blues')
    plt.colorbar(label='|Correlation|')
    plt.xlabel('Factor (Digit Class)')
    plt.ylabel('Latent Dimension')
    plt.title('Latent Dimension – Factor Correlation')
    plt.tight_layout()
    plt.savefig('disentanglement_matrix.png', dpi=150)
    plt.show()
```

### DCI Disentanglement Score

The Disentanglement-Completeness-Informativeness (DCI) framework (Eastwood & Williams, 2018) provides a comprehensive evaluation:

```python
def compute_dci_disentanglement(importance_matrix):
    """
    Compute DCI disentanglement score from importance matrix.
    
    Importance matrix R[i,j] = how important latent dim i is 
    for predicting factor j.
    
    Disentanglement: Each latent dim should predict at most one factor.
    Completeness: Each factor should be predicted by at most one latent dim.
    """
    R = importance_matrix / (importance_matrix.sum(axis=1, keepdims=True) + 1e-8)
    
    # Disentanglement: entropy of each row should be low
    # (each latent dim concentrated on one factor)
    from scipy.stats import entropy
    
    disentanglement_scores = []
    for i in range(R.shape[0]):
        if R[i].sum() > 0:
            H = entropy(R[i] + 1e-8)
            H_max = np.log(R.shape[1])
            disentanglement_scores.append(1 - H / H_max)
    
    # Weight by importance
    weights = importance_matrix.sum(axis=1)
    weights = weights / (weights.sum() + 1e-8)
    
    disentanglement = np.average(disentanglement_scores, weights=weights[:len(disentanglement_scores)])
    
    return disentanglement
```

---

## Encouraging Disentanglement

### Strategy 1: Latent Decorrelation

Add a penalty that encourages latent dimensions to be uncorrelated:

```python
def decorrelation_loss(z):
    """
    Penalize correlation between latent dimensions.
    
    Computes the off-diagonal elements of the correlation matrix
    and penalizes their magnitude.
    """
    batch_size = z.shape[0]
    
    # Center the latent codes
    z_centered = z - z.mean(dim=0, keepdim=True)
    
    # Compute correlation matrix
    cov = (z_centered.T @ z_centered) / (batch_size - 1)
    std = torch.sqrt(torch.diag(cov) + 1e-8)
    corr = cov / (std.unsqueeze(0) * std.unsqueeze(1))
    
    # Penalty: sum of squared off-diagonal correlations
    mask = ~torch.eye(corr.shape[0], dtype=torch.bool, device=z.device)
    penalty = torch.sum(corr[mask] ** 2)
    
    return penalty
```

### Strategy 2: Total Correlation Penalty

Minimize the total correlation (TC) of the latent distribution, which measures the dependency between latent dimensions:

$$\text{TC}(z) = \text{KL}\left[q(z) \,\|\, \prod_i q(z_i)\right]$$

This is the approach taken by β-TC-VAE (Chen et al., 2018), but can be approximated for deterministic autoencoders.

### Strategy 3: Group-wise Regularization

Assign latent dimensions to groups and encourage each group to capture distinct aspects of the data:

```python
class DisentangledAutoencoder(nn.Module):
    """
    Autoencoder with decorrelation penalty for disentanglement.
    """
    
    def __init__(self, input_dim=784, latent_dim=32):
        super().__init__()
        self.latent_dim = latent_dim
        
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim),
        )
        
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, input_dim),
            nn.Sigmoid()
        )
    
    def encode(self, x):
        return self.encoder(x)
    
    def decode(self, z):
        return self.decoder(z)
    
    def forward(self, x):
        z = self.encode(x)
        return self.decode(z), z


def train_disentangled_ae(model, train_loader, device, 
                          decorr_weight=0.1, num_epochs=15):
    """
    Train autoencoder with decorrelation penalty.
    
    Loss = Reconstruction + λ_decorr × Decorrelation Penalty
    """
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    recon_criterion = nn.MSELoss()
    
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        
        for images, _ in train_loader:
            images = images.view(images.size(0), -1).to(device)
            
            optimizer.zero_grad()
            recon, z = model(images)
            
            recon_loss = recon_criterion(recon, images)
            decorr_loss = decorrelation_loss(z)
            
            loss = recon_loss + decorr_weight * decorr_loss
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        print(f"Epoch {epoch+1}: Loss = {total_loss/len(train_loader):.6f}")
```

---

## Dimension Traversal Visualization

The most intuitive way to assess disentanglement is to vary one latent dimension while holding others fixed:

```python
def traverse_latent_dimensions(model, test_loader, device, 
                                num_dims=10, num_steps=11):
    """
    Traverse individual latent dimensions to visualize
    what each dimension encodes.
    
    For a disentangled model, each row should show a single
    factor changing (e.g., only thickness, only slant).
    """
    model.eval()
    
    # Get a reference point
    images, _ = next(iter(test_loader))
    image = images[0:1].view(1, -1).to(device)
    
    with torch.no_grad():
        z_ref = model.encode(image)
    
    num_dims = min(num_dims, z_ref.shape[1])
    
    fig, axes = plt.subplots(num_dims, num_steps, 
                             figsize=(num_steps * 1.2, num_dims * 1.2))
    
    with torch.no_grad():
        for dim_idx in range(num_dims):
            # Range of values to traverse
            z_values = torch.linspace(-3, 3, num_steps)
            
            for step_idx, val in enumerate(z_values):
                z_modified = z_ref.clone()
                z_modified[0, dim_idx] = val
                
                recon = model.decode(z_modified)
                img = recon.cpu().numpy().reshape(28, 28)
                
                axes[dim_idx, step_idx].imshow(img, cmap='gray')
                axes[dim_idx, step_idx].axis('off')
            
            axes[dim_idx, 0].set_ylabel(f'z_{dim_idx}', fontsize=8)
    
    plt.suptitle('Latent Dimension Traversals')
    plt.tight_layout()
    plt.savefig('dimension_traversals.png', dpi=150)
    plt.show()
```

---

## Quantitative Finance Application

Disentanglement is particularly valuable in quantitative finance:

- **Factor interpretability:** Disentangled latent dimensions correspond to interpretable risk factors (e.g., market beta, size, value, momentum) rather than opaque linear combinations
- **Risk attribution:** With disentangled factors, portfolio risk can be cleanly attributed to individual sources without cross-contamination between factors
- **Conditional analysis:** Disentangled representations enable conditional reasoning — e.g., "what happens to this portfolio if only the interest rate factor changes while all other factors remain constant?"
- **Regime factors:** One latent dimension might capture market regime (risk-on vs risk-off) independently of sector rotation factors

---

## Exercises

### Exercise 1: Disentanglement Measurement
Train standard and decorrelation-regularized autoencoders on MNIST. Compute and compare the axis alignment scores. Does the decorrelation penalty improve disentanglement?

### Exercise 2: Dimension Traversals
Generate dimension traversal plots for both models. Identify which dimensions capture interpretable factors (digit identity, thickness, slant).

### Exercise 3: Correlation Matrix Analysis
Compute the correlation matrix of latent codes for both models. Visualize and compare — the decorrelated model should have a more diagonal structure.

### Exercise 4: Factor Recovery
For a synthetic dataset with known generative factors, measure how well each latent dimension recovers each true factor using mutual information.

---

## Summary

| Concept | Key Point |
|---------|-----------|
| **Disentanglement** | Each latent dimension captures one independent factor |
| **Axis alignment** | Measures correlation between latent dims and known factors |
| **Decorrelation penalty** | Explicitly penalizes statistical dependence between latent dims |
| **Traversal visualization** | Most intuitive assessment of what each dimension encodes |
| **Limitation** | Standard autoencoders have no theoretical guarantee of disentanglement; VAEs with β > 1 provide stronger inductive bias |

**Key Insight:** While standard autoencoders can learn partially disentangled representations, achieving true disentanglement typically requires explicit regularization. The decorrelation penalty provides a simple but effective approach, though probabilistic models (β-VAE) offer stronger theoretical guarantees. In quantitative finance, disentangled factors are essential for interpretable risk decomposition.

---

## References

- Bengio, Y., Courville, A., & Vincent, P. (2013). "Representation Learning: A Review and New Perspectives." *IEEE TPAMI*.
- Eastwood, C., & Williams, C. K. I. (2018). "A Framework for the Quantitative Evaluation of Disentangled Representations." *ICLR*.
- Chen, R. T. Q., et al. (2018). "Isolating Sources of Disentanglement in VAEs." *NeurIPS*.
