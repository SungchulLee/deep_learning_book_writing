# Synthetic Financial Data Generation

Diffusion models can generate **synthetic financial datasets** that preserve the statistical properties of real data while providing privacy guarantees, augmenting limited samples, and enabling reproducible research.

## Use Cases

### Privacy-Preserving Data Sharing

Financial institutions hold proprietary datasets that cannot be shared due to regulatory and competitive constraints. Synthetic data generated by a well-trained diffusion model can be shared freely while preserving the statistical properties needed for downstream analysis.

### Data Augmentation for ML Models

Many financial ML tasks suffer from limited dataâ€”especially for rare events (crises, defaults, tail risks). Diffusion models can generate additional training examples that augment the real dataset, improving model robustness.

### Backtesting Under Novel Regimes

Generate synthetic data that extrapolates beyond observed history, creating plausible market environments for testing trading strategies under conditions not present in the historical record.

## Synthetic Data Quality Metrics

### Fidelity Metrics

Measure how well synthetic data matches real data statistics:

| Metric | Description |
|--------|-------------|
| Marginal distributions | Per-feature distributional match (KS, Wasserstein) |
| Correlation matrix distance | $\|\Sigma_{\text{real}} - \Sigma_{\text{synth}}\|_F / \|\Sigma_{\text{real}}\|_F$ |
| Higher moments | Skewness, kurtosis per feature |
| Temporal statistics | ACF, partial ACF, volatility clustering |

### Privacy Metrics

Ensure synthetic data does not leak individual records:

| Metric | Description |
|--------|-------------|
| Nearest-neighbour distance | Minimum distance from synthetic to real points |
| Membership inference | Can an attacker determine if a record was in training data? |
| Attribute inference | Can sensitive attributes be inferred from synthetic data? |

### Utility Metrics

Verify synthetic data is useful for downstream tasks:

| Metric | Description |
|--------|-------------|
| Train-on-synthetic, test-on-real (TSTR) | ML model trained on synthetic data, evaluated on real |
| Train-on-real, test-on-synthetic (TRTS) | Complementary check |
| Feature importance preservation | Do models learn the same feature rankings? |

## Implementation Pipeline

```python
import torch
import torch.nn as nn
import numpy as np


class SyntheticDataPipeline:
    """End-to-end pipeline for synthetic financial data generation."""

    def __init__(
        self,
        model: nn.Module,
        T: int = 1000,
        beta_start: float = 1e-4,
        beta_end: float = 0.02,
    ):
        self.model = model
        self.T = T
        betas = torch.linspace(beta_start, beta_end, T)
        self.alphas = 1.0 - betas
        self.alpha_bars = torch.cumprod(self.alphas, dim=0)
        self.betas = betas

    def fit(
        self,
        data: torch.Tensor,
        n_epochs: int = 5000,
        batch_size: int = 256,
        lr: float = 1e-3,
    ):
        """Train diffusion model on real data.

        Args:
            data: Real financial data [N, D].
            n_epochs: Training epochs.
            batch_size: Batch size.
            lr: Learning rate.
        """
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)

        for epoch in range(n_epochs):
            idx = torch.randperm(len(data))[:batch_size]
            x_0 = data[idx]
            B = x_0.shape[0]

            t = torch.randint(0, self.T, (B,))
            eps = torch.randn_like(x_0)

            a_bar = self.alpha_bars[t].unsqueeze(-1)
            x_t = torch.sqrt(a_bar) * x_0 + torch.sqrt(1 - a_bar) * eps

            eps_pred = self.model(x_t, t.float() / self.T)
            loss = ((eps - eps_pred) ** 2).mean()

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (epoch + 1) % 1000 == 0:
                print(f"Epoch {epoch+1}: loss = {loss.item():.6f}")

    @torch.no_grad()
    def generate(self, n_samples: int) -> torch.Tensor:
        """Generate synthetic samples via DDPM sampling.

        Args:
            n_samples: Number of synthetic samples.

        Returns:
            Synthetic data [n_samples, D].
        """
        dim = next(self.model.parameters()).shape[-1]  # Infer from model
        x = torch.randn(n_samples, dim)

        for t in reversed(range(self.T)):
            t_batch = torch.full((n_samples,), t / self.T)
            eps_pred = self.model(x, t_batch)

            alpha_t = self.alphas[t]
            alpha_bar_t = self.alpha_bars[t]
            mu = (1 / torch.sqrt(alpha_t)) * (
                x - (1 - alpha_t) / torch.sqrt(1 - alpha_bar_t) * eps_pred
            )

            if t > 0:
                x = mu + torch.sqrt(self.betas[t]) * torch.randn_like(x)
            else:
                x = mu

        return x

    def evaluate_fidelity(
        self, real: torch.Tensor, synthetic: torch.Tensor
    ) -> dict:
        """Basic fidelity metrics."""
        real_np = real.numpy()
        synth_np = synthetic.numpy()

        # Per-feature KS statistics
        from scipy.stats import ks_2samp
        ks_stats = [
            ks_2samp(real_np[:, i], synth_np[:, i]).statistic
            for i in range(real_np.shape[1])
        ]

        # Correlation matrix distance
        corr_real = np.corrcoef(real_np.T)
        corr_synth = np.corrcoef(synth_np.T)
        corr_dist = np.linalg.norm(corr_real - corr_synth, 'fro')
        corr_dist_norm = corr_dist / np.linalg.norm(corr_real, 'fro')

        # Moment comparison
        mean_err = np.abs(real_np.mean(0) - synth_np.mean(0)).mean()
        std_err = np.abs(real_np.std(0) - synth_np.std(0)).mean()

        return {
            'mean_ks_stat': float(np.mean(ks_stats)),
            'max_ks_stat': float(np.max(ks_stats)),
            'corr_matrix_distance': float(corr_dist_norm),
            'mean_abs_error': float(mean_err),
            'std_abs_error': float(std_err),
        }
```

## Best Practices

**Normalisation matters.** Financial data often has heavy tails. Normalise to zero mean and unit variance, or apply rank-based transformations before training.

**Validate thoroughly.** Always compare synthetic and real data across multiple metrics. A model that matches marginals may fail on correlations or temporal structure.

**Document limitations.** Synthetic data is only as good as the training data. It cannot generate scenarios outside the support of the training distribution (without explicit extrapolation mechanisms).

**Combine with domain knowledge.** Use conditional generation to enforce known constraints (e.g., positive prices, budget constraints, no-arbitrage conditions).

## References

1. Assefa, S., et al. (2020). "Generating Synthetic Data in Finance: Opportunities, Challenges and Pitfalls." *NeurIPS Workshop*.
2. Jordon, J., Yoon, J., & van der Schaar, M. (2019). "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees." *ICLR*.
