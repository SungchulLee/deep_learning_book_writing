# Step 1: Attention Review (from RNNs)
## Introduction
Understanding the original attention mechanism from RNN seq2seq models.
## Files
- attention_mechanisms.py - Bahdanau and Luong attention
- rnn_attention.py - RNN with attention
- seq2seq_with_attention.py - Complete seq2seq model
- train_translation.py - Training script
